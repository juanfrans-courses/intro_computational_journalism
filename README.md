# Introduction to Computational Journalism
Journalists who can identify, refine, and interrogate the information they need within a large data set are in-demand and publishing the most exciting work in the industry. The *Introduction to Computational Journalism* course at Columbia Journalism School, teaches the fundamentals: how to scrape data from the web, digitize PDFs and use other digital sources to compile your own data sets; a primer on Python and its most popular data analysis library, Pandas; and how to build your initial analysis and visualizations.

### Prerequisites
This data journalism course is designed for those with basic analytic skills or experience (Excel and/or databases). All students will need a laptop with administrative install abilities.

### Objectives
* Find stories within the data, and work within your team and newsroom to report them out
* Learn the fundamentals of Python and the Python data analysis tool Pandas
* Scrape and clean publicly available data from the web
* Automatically submit online forms and scrape the results
* Convert tabular data from PDFs into spreadsheet-compatible formats
* Extract text from PDF images of documents (OCR)
* Combine multiple data sets
* Perform exploratory data analysis and visualization

### The School
The Columbia University Graduate School of Journalism is the premiere institution for the study and practice of journalism in the world. Led by our award-winning faculty of active reporters, editors, filmmakers and digital media specialists, our programs are intensive, rigorous, and demanding. Our professional development programs, fellowships and workshops offer opportunities for seasoned practitioners and media executives to advance their knowledge and expertise.

## Course Syllabus
Course time will be full-day, Monday through Friday. Instruction time will be divided between short lectures (90-120 minutes) and exercises done individually and in small teams.

### Monday, June 3
[*Basic data analysis (Excel / Google Sheets / Open Refine / PDFs)*](01_Excel_GoogleSheets_OpenRefine_PDFs/01_Excel_GoogleSheets_OpenRefine_PDFs.md)
* Introductions and overall plan for the week
* Data processing & organization: workflow and principles
  * Raw data and data wrangling
  * Suggested data and file organization
* Basic data analysis in *Excel* & *Google Sheets*:
  * Loading different types of data (`.csv` & `.txt`)
  * Performing basic summary calculations
  * Writing and copying formulas
  * Cleaning and wrangling data:
    * Splitting columns, concatenating, selecting n characters to the left or right
    * Find and replace
    * Wildcards (`*`, `?`, `~`)
  * Useful functions:
    * `if` statements and similar functions (`countif`, `sumif` and `sumifs`)
    * Retrieving specific values from tables (`index`, `match`, `vlookup`)
    * Merging tables with `index` + `match` or `vlookup`
  * Creating a frequency distribution table and histograms
  * Pivot tables
  * Exporting data (`.csv` & `.txt`)
* Extracting tables from *PDFs*
* *Python* installation troubleshooting